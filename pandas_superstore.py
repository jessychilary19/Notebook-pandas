# -*- coding: utf-8 -*-
"""Pandas_SuperStore.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gvn15fk9A-tCHDshGxCPGvRUrARpEhj1

# Importando o PANDAS
"""

import pandas as pd

"""URL DO DOCUMENTO"""

url='https://raw.githubusercontent.com/alura-cursos/Pandas/refs/heads/main/superstore_data.csv'

dados_mercado=pd.read_csv(url)

"""VISUALIZANDO DADOS"""

dados_mercado.head()

url_2='https://raw.githubusercontent.com/alura-cursos/Pandas/refs/heads/main/superstore_data_ponto_virgula.csv'

dados_ponto_virgula=pd.read_csv(url_2)

dados_ponto_virgula.head()

"""BIBLIOTECA CHARDET PARA DETECTAR O ENCODING DE UM ARQUIVO TIPO CSV"""

import chardet

"""SEP PARA AJUSTAR EM PONTO VIRGULA

"""

dados_sem_virgula=pd.read_csv(url_2,sep=';')

dados_sem_virgula.head()

dados_primeiras_linhas= pd.read_csv(url,nrows=5)
dados_primeiras_linhas

"""VISUALIZAR OS DADOS SOMENTE DAS COLUNAS (ID, ANIVERSÁRIO, RENDIMENTO)"""

dados_selecao=pd.read_csv(url,usecols=['Id','Year_Birth','Income'])
dados_selecao

dados_selecao=pd.read_csv(url,usecols=[0,1,4])
dados_selecao

"""SALVANDO EM CSV"""

dados_selecao.to_csv('Clientes_mercado.csv')

Clientes_mercado=pd.read_csv('/content/Clientes_mercado.csv')

Clientes_mercado

"""RETIRANDO COLUNAS DESNECESSÁRIAS"""

dados_selecao.to_csv('dados_mercado.csv',index= False)

dados_mercado=pd.read_csv('/content/dados_mercado.csv')
dados_mercado

"""TRABALHANDO COM EXCEL"""

import pandas as pd

url= 'https://github.com/alura-cursos/Pandas/blob/main/emissoes_CO2.xlsx?raw=True'

dados_co2= pd.read_excel(url)

dados_co2.head()

"""EXISTEM MAIS PLANILHA DENTRO DESSA PLANILHA?"""

pd.ExcelFile(url).sheet_names

percapita= pd.read_excel(url, sheet_name= 'emissoes_percapita')

percapita.head()

fontes= pd.read_excel(url, sheet_name= 'fontes')

fontes.head()

"""EXIBINDO COLUNAS APENAS"""

intervalo = pd.read_excel(url,sheet_name= 'emissoes_C02',usecols='A:D')

intervalo

intervalo2 = pd.read_excel(url,sheet_name= 'emissoes_C02',usecols='A:D',nrows=10)

intervalo2

percapita.to_excel('CO2_percapita.xlsx', index=False)

pd.read_excel('/content/CO2_percapita.xlsx')

"""MANIPULANDO ARQUIVOS TIPO JSON (JAVA SCRIPT NOTAÇÃO)"""

import pandas as pf

dados_pacientes= pd.read_json('/content/pacientes.json')

dados_pacientes

dados_pacientes2= pd.read_json('/content/pacientes_2.json')

dados_pacientes2

"""NORMALIZAÇÃO DOS ARQUIVOS JSON"""

df_normalizado = pd.json_normalize(dados_pacientes2['Pacientes'])

df_normalizado

df_normalizado.to_json('historico_pacientes_normalizado.json')

pd.read_json('/content/historico_pacientes_normalizado.json')

"""APIS EM JSON"""

import requests
import json

dados_usuarios = requests.get('https://jsonplaceholder.typicode.com/users')

resultado = json.loads(dados_usuarios.text)

pd.DataFrame(resultado)

import pandas as pd
dados_usuarios_normalizado = pd.json_normalize(resultado, sep='_')

dados_usuarios_normalizado

"""Extraindo dados de uma pagina Web (HTML) e XML"""

import pandas as pd

dados_html= pd.read_html('/content/filmes_wikipedia.html')
dados_html

len(dados_html)

top_filmes=dados_html[1]
top_filmes

top_filmes.to_html('top_filmes.html')

top_filmes.to_csv('top_filmes_1998.csv', index=False)

pd.read_csv('/content/top_filmes_1998.csv')

import pandas as pd

dados_imdb=pd.read_xml('/content/imdb_top_1000.xml')
dados_imdb.head(3)

dados_imdb.to_xml('filmes_imdb.xml')

"""BANCO DE DADOS COM PANDAS"""

import pandas as pd
import sqlalchemy

sqlalchemy.__version__

pip install --upgrade 'sqlalchemy<2.0'

import sqlalchemy

from sqlalchemy import create_engine, MetaData, Table, inspect

engine=create_engine('sqlite:///:memory:')

url= 'https://raw.githubusercontent.com/alura-cursos/Pandas/refs/heads/main/clientes_banco.csv'

import pandas as pd

dados=pd.read_csv(url)
dados.head()

connection = engine.connect()

import sqlalchemy
from sqlalchemy import create_engine, MetaData, Table, inspect
engine = create_engine('sqlite:///:memory:')

import pandas as pd
url = 'https://raw.githubusercontent.com/alura-cursos/Pandas/main/clientes_banco.csv'
dados = pd.read_csv(url)
dados.to_sql('clientes', engine, index=False)

pd.read_sql_table('clientes', engine)

query = 'UPDATE Clientes SET Rendimento_anual=300000.0 WHERE ID_Cliente=6840104' with engine.connect() as conn: conn.execute(text(query)) conn.commit()